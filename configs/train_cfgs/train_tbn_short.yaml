batch_size: 1
num_workers: 4
n_epochs: 3
lr_steps: [1]  # Epochs to decay learning rate by 10
print_freq: 20  # Print frequency
clip_gradient: 20.0  # Gradient norm clipping. Default = None
partialbn: True 
freeze: False  # freeze all weights except fusion
eval_freq: 1
pretrain_flow_weight: True
optimizer: 'SGD'
optim_params:
    lr: 0.01
    momentum: 0.9
    weight_decay: 5.e-4
